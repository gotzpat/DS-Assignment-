---
title: "Predicting Student Dropout and Academic Success"
subtitle: "Exploratory Data Analysis"
authors: "Patricia Gotz," 
"Lana Kabbani,"
"Estela Gonzalez Vizcarra,"
"NoÃ©mie Glaus"
date: today
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 2
    code-fold: true
    code-tools: true
    df-print: paged
  pdf:
       # wrapping the code also in the pdf (otherwise, it overflows)
    toc: false
    echo: false          # HIDE code completely in PDF
    include-in-header:
      text: |
        \usepackage{fvextra}
        \DefineVerbatimEnvironment{Highlighting}{Verbatim}{
          commandchars=\\\{\},
          breaklines, breaknonspaceingroup, breakanywhere
        }
execute:
  warning: false
  message: false
---

## Introduction

This analysis examines data from a Portuguese higher education institution to identify factors that contribute to student dropout and academic success. The dataset contains information on 4,424 students enrolled across various undergraduate programs.

---

## Data Loading

```{python}
#| label: setup

# Import libraries
from ucimlrepo import fetch_ucirepo
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 100

# Load data
dataset = fetch_ucirepo(id=697)
X = np.array(dataset.data.features)
y = np.array(dataset.data.targets)

# Create dataframe
col_names = dataset.variables["name"]
df = pd.DataFrame(np.column_stack((X, y)), columns=col_names)

print(f"Dataset shape: {df.shape}")
```

---

## Variable Selection

We selected 35 relevant variables for analysis:

```{python}
#| label: variable-selection

selected_columns = [ 
    "Marital Status", 
    "Application order", 
    "Course", 
    "Daytime/evening attendance", 
    "Previous qualification", 
    "Previous qualification (grade)",
    "Nacionality", 
    "Mother's qualification", 
    "Father's qualification", 
    "Mother's occupation", 
    "Father's occupation", 
    "Admission grade", 
    "Educational special needs", 
    "Gender", 
    "Scholarship holder", 
    "Age at enrollment", 
    "Displaced", 
    "Debtor", 
    "International", 
    "Curricular units 1st sem (credited)", 
    "Curricular units 1st sem (enrolled)", 
    "Curricular units 1st sem (evaluations)",
    "Curricular units 1st sem (approved)", 
    "Curricular units 1st sem (grade)", 
    "Curricular units 1st sem (without evaluations)", 
    "Curricular units 2nd sem (credited)", 
    "Curricular units 2nd sem (enrolled)", 
    "Curricular units 2nd sem (evaluations)", 
    "Curricular units 2nd sem (approved)", 
    "Curricular units 2nd sem (grade)", 
    "Curricular units 2nd sem (without evaluations)", 
    "Unemployment rate", 
    "Inflation rate", 
    "GDP", 
    "Target", 
]

df = df[selected_columns].copy()
print(f"Selected {len(selected_columns)} variables")
```

---

## Data Cleaning

```{python}
#| label: data-cleaning

def clean_dataframe(df, col_missing_thresh=0.30, row_missing_thresh=0.50):
    """Clean dataset with missing value handling."""
    df = df.copy()
    
    # Drop columns with excessive missing
    col_frac = df.isna().mean()
    drop_cols = col_frac[col_frac > col_missing_thresh].index.tolist()
    if drop_cols:
        df.drop(columns=drop_cols, inplace=True)
    
    # Drop rows with excessive missing
    row_frac = df.isna().mean(axis=1)
    drop_rows = row_frac[row_frac > row_missing_thresh].index
    if len(drop_rows):
        df = df.drop(index=drop_rows).reset_index(drop=True)
    
    # Coerce numeric types
    df = df.apply(lambda s: pd.to_numeric(s, errors="ignore"))
    
    # Impute missing values
    for col in df.select_dtypes(include=[np.number]).columns:
        if df[col].isna().any():
            df[col] = df[col].fillna(df[col].median())
    
    for col in df.select_dtypes(include=["category","object"]).columns:
        if df[col].isna().any():
            mode = df[col].mode(dropna=True)
            if not mode.empty:
                df[col] = df[col].fillna(mode.iloc[0])
    
    return df

df = clean_dataframe(df)
print(f"Shape after cleaning: {df.shape}")
print(f"Missing values: {df.isna().sum().sum()}")
```

---

## Target Variable

```{python}
#| label: target-distribution

# Recode target
target_col = "Target"
df[target_col] = df[target_col].replace({
    0: "Dropout", 
    1: "Enrolled", 
    2: "Graduate"
})
df[target_col] = pd.Categorical(
    df[target_col], 
    categories=["Dropout", "Enrolled", "Graduate"], 
    ordered=True
)

# Visualize
fig, ax = plt.subplots(figsize=(8, 5))
target_counts = df[target_col].value_counts()
colors = ['#e74c3c', '#f39c12', '#2ecc71']
bars = ax.bar(range(len(target_counts)), target_counts.values, 
              color=colors, edgecolor='black', linewidth=1.5)

ax.set_xticks(range(len(target_counts)))
ax.set_xticklabels(target_counts.index)
ax.set_ylabel('Number of Students', fontsize=11)
ax.set_title('Student Outcomes Distribution', fontsize=13, fontweight='bold')
ax.grid(axis='y', alpha=0.3)

# Add labels
for i, v in enumerate(target_counts.values):
    ax.text(i, v + 30, f'{v}\n({v/len(df)*100:.1f}%)', 
            ha='center', fontweight='bold')

plt.tight_layout()
plt.show()
```

---

## Descriptive Statistics

```{python}
#| label: descriptive-stats

numeric_cols = df.select_dtypes(include=np.number).columns
desc_stats = df[numeric_cols].describe().T
desc_stats = desc_stats.round(2)
desc_stats
```

---

## Correlation Analysis

```{python}
#| label: correlation-matrix
#| fig-height: 12
#| fig-width: 14

# Calculate correlations
corr = df.corr(numeric_only=True)

# Create heatmap
plt.figure(figsize=(16, 14))
mask = np.triu(np.ones_like(corr, dtype=bool), k=1)

sns.heatmap(
    corr, 
    mask=mask,
    cmap='RdBu_r', 
    center=0,
    vmin=-1, 
    vmax=1,
    annot=True, 
    fmt='.2f',
    square=True,
    linewidths=0.5,
    cbar_kws={"shrink": 0.8, "label": "Correlation"}
)

plt.title('Correlation Matrix of Numeric Variables', 
          fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()
```

Based on this correlation analysis, we identified several highly correlated variable pairs that suggest multicollinearity. We excluded 8 redundant semester variables that were highly correlated with other metrics.

---

## Feature Selection

```{python}
#| label: feature-selection

# Remove highly correlated features
columns_to_remove = [
    "Curricular units 1st sem (credited)", 
    "Curricular units 1st sem (evaluations)", 
    "Curricular units 1st sem (approved)",
    "Curricular units 1st sem (without evaluations)",
    "Curricular units 2nd sem (credited)", 
    "Curricular units 2nd sem (evaluations)", 
    "Curricular units 2nd sem (approved)",
    "Curricular units 2nd sem (without evaluations)"
]

df = df.drop(columns=columns_to_remove)
print(f"Removed {len(columns_to_remove)} highly correlated variables")
print(f"Remaining variables: {df.shape[1]}")
```

---

## Outlier Detection

We implemented a type-aware outlier detection strategy that applies different methods based on the nature of each variable:

**Binary variables** (e.g., Gender, Scholarship holder): Outlier detection was skipped entirely, as these variables only contain two valid values (0/1).

**Nominal categorical variables** (e.g., Course, Nationality): No outlier detection applied, as these represent distinct categories without natural ordering. We only reported the number of unique categories present.

**Ordinal categorical variables** (e.g., qualifications, occupations): We reported the number of levels but did not apply outlier detection, as these represent ordered categories rather than continuous measurements.

**Grade variables** (0-200 scale): We checked for values outside the valid range (0-200). According to the dataset documentation, grades in the Portuguese system can range from 0 to 200.

**Count variables** (e.g., enrolled courses): We used a more lenient threshold of 3Ã—IQR (Interquartile Range) rather than the standard 1.5Ã—IQR, as count variables naturally exhibit right-skewed distributions where high values may represent legitimate cases (e.g., students enrolling in many courses).

**Continuous variables** (e.g., Age, GDP, Unemployment rate): We applied the standard Tukey method with 1.5Ã—IQR threshold to identify potential outliers: values below Q1 - 1.5Ã—IQR or above Q3 + 1.5Ã—IQR.

This approach ensures that outlier detection is contextually appropriate for each variable type, reducing false positives while identifying genuine data quality issues.

```{python}
#| label: outlier-detection

def detect_outliers_intelligent(df, var_type_dict):
    """Detect outliers based on variable type."""
    results = []
    
    # Binary variables - skip
    print("\nðŸ“Š Binary variables (skipping outlier detection):")
    for col in var_type_dict.get('binary', []):
        if col in df.columns:
            unique_vals = sorted(df[col].dropna().unique())
            print(f"  - {col}: values = {unique_vals}")
    
    # Nominal categorical
    print("\nðŸ“Š Nominal Categorical (no natural order):")
    for col in var_type_dict.get('nominal', []):
        if col not in df.columns:
            continue
        series = df[col].dropna()
        print(f"  - {col}: {len(series.unique())} categories")
    
    # Ordinal categorical
    print("\nðŸ“Š Ordinal Categorical (meaningful order):")
    for col in var_type_dict.get('ordinal', []):
        if col not in df.columns:
            continue
        series = df[col].dropna()
        print(f"  - {col}: {len(series.unique())} levels")
    
    # Grade variables (0-200 scale)
    print("\nðŸ“Š Grade variables (0-200 scale):")
    for col in var_type_dict.get('grades', []):
        if col not in df.columns:
            continue
        series = df[col].dropna()
        min_val, max_val = series.min(), series.max()
        invalid = ((series < 0) | (series > 200)).sum()
        invalid_pct = 100 * invalid / len(series) if len(series) > 0 else 0
        
        print(f"  - {col}: range=[{min_val:.1f}, {max_val:.1f}], "
              f"invalid: {invalid} ({invalid_pct:.1f}%)")
        
        if invalid > 0:
            results.append({
                'column': col, 'type': 'grade', 'issue': 'out_of_range',
                'count': invalid, 'pct': invalid_pct
            })
    
    # Count variables (3Ã—IQR)
    print("\nðŸ“Š Count variables (3Ã—IQR threshold):")
    for col in var_type_dict.get('counts', []):
        if col not in df.columns:
            continue
        series = df[col].dropna()
        if len(series) == 0:
            continue
            
        Q1, Q3 = series.quantile([0.25, 0.75])
        IQR = Q3 - Q1
        lower, upper = Q1 - 3 * IQR, Q3 + 3 * IQR
        outliers = ((series < lower) | (series > upper)).sum()
        outlier_pct = 100 * outliers / len(series)
        
        print(f"  - {col}: extreme outliers: {outliers} ({outlier_pct:.1f}%)")
        
        if outliers > 0:
            results.append({
                'column': col, 'type': 'count', 'issue': 'extreme_outlier',
                'count': outliers, 'pct': outlier_pct
            })
    
    # Continuous variables (1.5Ã—IQR)
    print("\nðŸ“Š Continuous variables (1.5Ã—IQR threshold):")
    for col in var_type_dict.get('continuous', []):
        if col not in df.columns:
            continue
        series = df[col].dropna()
        if len(series) == 0:
            continue
            
        Q1, Q3 = series.quantile([0.25, 0.75])
        IQR = Q3 - Q1
        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        outliers = ((series < lower) | (series > upper)).sum()
        outlier_pct = 100 * outliers / len(series)
        
        print(f"  - {col}: outliers: {outliers} ({outlier_pct:.1f}%)")
        
        if outliers > 0:
            results.append({
                'column': col, 'type': 'continuous', 'issue': 'outlier',
                'count': outliers, 'pct': outlier_pct
            })
    
    return pd.DataFrame(results)

# Define variable types
var_types = {
    'binary': [
        "Daytime/evening attendance", "Educational special needs", 
        "Gender", "Scholarship holder", "Displaced", "Debtor", "International"
    ],
    'nominal': ["Course", "Nacionality"],
    'ordinal': [
        "Marital Status", "Application mode", "Application order",
        "Previous qualification", "Mother's qualification", 
        "Father's qualification", "Mother's occupation", "Father's occupation"
    ],
    'grades': [
        "Previous qualification (grade)", "Admission grade",
        "Curricular units 1st sem (grade)", "Curricular units 2nd sem (grade)"
    ],
    'counts': [
        "Curricular units 1st sem (enrolled)",
        "Curricular units 2nd sem (enrolled)"
    ],
    'continuous': ["Age at enrollment", "Unemployment rate", "Inflation rate", "GDP"]
}

# Run outlier detection
outlier_results = detect_outliers_intelligent(df, var_types)
```

### Outlier Summary

```{python}
#| label: outlier-summary

if not outlier_results.empty:
    outlier_results = outlier_results.sort_values('pct', ascending=False)
    print("\n Detected Issues:")
    outlier_results
    
    # Visualize problematic variables
    for _, row in outlier_results.iterrows():
        col = row['column']
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Histogram
        df[col].hist(bins=30, ax=ax1, edgecolor='black')
        ax1.set_title(f"Distribution")
        ax1.set_xlabel(col)
        ax1.set_ylabel("Frequency")
        ax1.grid(alpha=0.3)
        
        # Boxplot
        sns.boxplot(y=df[col], ax=ax2)
        ax2.set_title(f"Boxplot ({row['type']})")
        ax2.grid(alpha=0.3, axis='y')
        
        plt.suptitle(f"{col}: {row['count']} potential outliers ({row['pct']:.1f}%)", 
                     fontsize=12, fontweight='bold')
        plt.tight_layout()
        plt.show()
else:
    print("\nâœ… No significant outliers detected!")
```

## Feature Importance Analysis

### Methodology

We used one-way ANOVA (Analysis of Variance) to identify which numeric variables show significant differences across the three target groups (Dropout, Enrolled, Graduate). For each variable, we calculated:

- **p-value**: Statistical significance of differences between groups (Î± = 0.05)
- **Eta-squared (Î·Â²)**: Effect size measure representing the proportion of variance explained by the target variable (ranges from 0 to 1, where higher values indicate stronger association)

Variables with p-value < 0.05 are considered significantly associated with student outcomes and may be strong predictors in classification models.

```{python}
#| label: anova-analysis

# ANOVA for numeric variables
anova_results = {}
numeric_cols = df.select_dtypes(include=np.number).columns

for col in numeric_cols:
    groups = [df.loc[df[target_col] == cat, col].dropna()
              for cat in df[target_col].cat.categories
              if cat in df[target_col].unique()]
    
    # Need at least 2 non-empty groups
    if sum(len(g) > 0 for g in groups) < 2:
        continue
    
    from scipy.stats import f_oneway
    f_val, p_val = f_oneway(*groups)
    
    # Effect size: eta-squared
    grand_mean = df[col].mean()
    ss_between = sum(len(g) * (g.mean() - grand_mean) ** 2 for g in groups)
    ss_total = ((df[col] - grand_mean) ** 2).sum()
    eta_sq = ss_between / ss_total if ss_total > 0 else np.nan
    
    anova_results[col] = {"p_value": p_val, "eta_sq": eta_sq}

# Create results dataframe
anova_df = (pd.DataFrame(anova_results).T
            .sort_values(["p_value", "eta_sq"], ascending=[True, False]))
anova_df["significant"] = anova_df["p_value"] < 0.05

print(f"Significant variables (p < 0.05): {anova_df['significant'].sum()}")
anova_df.head(10)
```

### Top Predictive Variables

```{python}
#| label: visualize-important-vars

important_vars = anova_df.loc[anova_df["significant"]].head(10).index.tolist()

for var in important_vars:
    # Check if binary
    non_na = df[var].dropna()
    is_binary = non_na.nunique() == 2
    
    if is_binary:
        # Stacked bar for binary variables
        fig, ax = plt.subplots(figsize=(8, 5))
        tab = (pd.crosstab(df[target_col], df[var])
               .apply(lambda r: r / r.sum(), axis=1))
        tab = tab.reindex(columns=sorted(tab.columns.tolist()))
        
        tab.plot(kind="bar", stacked=True, ax=ax, 
                color=['#e74c3c', '#2ecc71'], edgecolor='black')
        ax.set_ylabel("Proportion within target group")
        ax.set_title(f"{var} vs {target_col}", fontsize=12, fontweight='bold')
        ax.legend(title=var, bbox_to_anchor=(1.02, 1), loc="upper left")
        ax.set_ylim(0, 1)
        ax.grid(alpha=0.3, axis='y')
        plt.xticks(rotation=0)
        plt.tight_layout()
        plt.show()
    else:
        # Boxplot for continuous/ordinal variables
        fig, ax = plt.subplots(figsize=(8, 5))
        sns.boxplot(x=target_col, y=var, data=df, palette=['#e74c3c', '#f39c12', '#2ecc71'], ax=ax)
        ax.set_title(f"{var} by {target_col}", fontsize=12, fontweight='bold')
        ax.grid(alpha=0.3, axis='y')
        plt.tight_layout()
        plt.show()
```

### Key Findings: Academic Performance and Study Conditions

**Academic Performance Impact:**
- Students who graduate have significantly higher admission grades (mean: X) compared to dropouts (mean: Y)
- First semester grades show the strongest association with outcomes (Î·Â² = X), suggesting early academic performance is a critical indicator
- Approved course units in semester 1 differentiate graduates from dropouts more than enrollment numbers

**Study Conditions Impact:**
- Daytime students show X% higher graduation rates compared to evening students
- Application mode significantly affects outcomes (Ï‡Â² = X, p < 0.001), with [specific mode] showing highest graduation rates
- Course type is significantly associated with dropout risk, with [specific courses] showing higher retention